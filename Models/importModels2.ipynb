{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a72f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s\\miniconda3\\envs\\samsungProj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc60af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit\"\n",
    "from transformers import BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    \n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s\\miniconda3\\envs\\samsungProj\\Lib\\site-packages\\transformers\\quantizers\\auto.py:226: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",         \n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43672f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated answer:\n",
      "USER: Write a Python function that implements a graph-based pathfinding algorithm to find the shortest path between two nodes in a weighted, undirected graph, considering both distance and cost constraints. The function should:\n",
      "1. Take a graph (as an adjacency list with weights and costs), start node, end node, and a maximum cost budget as input.\n",
      "2. Return the shortest path (list of nodes) that respects the cost budget, or None if no valid path exists.\n",
      "3. Use Dijkstra’s algorithm with a modified priority queue to account for both distance and cost.\n",
      "4. Include error handling for invalid inputs (e.g., negative weights, non-existent nodes).\n",
      "5. Provide an example usage with a graph containing at least 5 nodes, demonstrating both a successful path and a case where no path fits the budget.\n",
      "\n",
      "Example graph format:\n",
      "graph = {\n",
      "    'A': {'B': (2, 5), 'C': (4, 10)},  # (distance, cost)\n",
      "    'B': {'A': (2, 5), 'D': (3, 8)},\n",
      "    'C': {'A': (4, 10), 'D': (1, 3), 'E': (5, 12)},\n",
      "    'D': {'B': (3, 8), 'C': (1, 3), 'E': (2, 6)},\n",
      "    'E': {'C': (5, 12), 'D': (2, 6)}\n",
      "AI: \n",
      "} ```python\n",
      "import heapq\n",
      "\n",
      "def find_shortest_path(graph, start, end, max_cost):\n",
      "    \"\"\"\n",
      "    Find the shortest path from start to end in a weighted, undirected graph\n",
      "    considering both distance and cost constraints.\n",
      "    \n",
      "    :param graph: Dictionary representing the graph as an adjacency list with weights and costs.\n",
      "    :param start: Starting node.\n",
      "    :param end: Ending node.\n",
      "    :param max_cost: Maximum cost budget.\n",
      "    :return: List of nodes representing the shortest path, or None if no valid path exists.\n",
      "    \"\"\"\n",
      "    if start not in graph or end not in graph:\n",
      "        raise ValueError(\"Start or end node does not exist in the graph.\")\n",
      "    \n",
      "    # Priority queue: (current_distance, current_cost, path)\n",
      "    pq = [(0, 0, [start])]\n",
      "    visited = set()\n",
      "    \n",
      "    while pq:\n",
      "        current_distance, current_cost, path = heapq.heappop(pq)\n",
      "        \n",
      "        if current_cost > max_cost:\n",
      "            continue\n",
      "        \n",
      "        if path[-1] == end:\n",
      "            return path\n",
      "        \n",
      "        if path[-1] in visited:\n",
      "            continue\n",
      "        \n",
      "        visited.add(path[-1])\n",
      "        \n",
      "        for neighbor, (weight, cost) in graph[path[-1]].items():\n",
      "            if weight < 0 or cost < 0:\n",
      "                raise ValueError(\"Graph contains negative weights or costs.\")\n",
      "            \n",
      "            new_distance = current_distance + weight\n",
      "            new_cost = current_cost + cost\n",
      "            \n",
      "            if new_cost <= max_cost and neighbor not in visited:\n",
      "                heapq.heappush(pq, (new_distance, new_cost, path + [neighbor]))\n",
      "    \n",
      "    return None\n",
      "\n",
      "# Example usage\n",
      "graph = {\n",
      "    'A': {'B': (2, 5), 'C': (4, 10)},\n",
      "    'B': {'A': (2, 5), 'D': (3, 8)},\n",
      "    'C': {'A': (4, 10), 'D': (1, 3), 'E': (5, 12)},\n",
      "    'D': {'B': (3, 8), 'C': (1, 3), 'E': (2, 6)},\n",
      "    'E': {'C': (5, 12), 'D': (2, 6)}\n",
      "}\n",
      "\n",
      "# Successful path within budget\n",
      "path_within_budget = find_shortest_path(graph, 'A', 'E', 20)\n",
      "print(\"Path within budget:\", path_within_budget)\n",
      "\n",
      "# No path within budget\n",
      "path_out_of_budget = find_shortest_path(graph, 'A', 'E', 15)\n",
      "print(\"Path out of budget:\", path_out_of_budget)\n",
      "```\n",
      "\n",
      "This code defines a function `find_shortest_path` that uses a modified Dijkstra's algorithm to find the shortest path in a graph considering both distance and cost constraints. It includes error handling for invalid inputs and demonstrates usage with an example graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (1, 315, 1000)) of distribution Categorical(probs: torch.Size([1, 315, 1000])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[[8.1848e-02, 3.8971e-02, 3.4515e-02,  ..., 2.3794e-04,\n          2.3794e-04, 2.3794e-04],\n         [1.6357e-01, 1.3232e-01, 9.1614e-02,  ..., 3.3736e-05,\n          3.3736e-05, 3.3736e-05],\n         [7.7295e-01, 7.7087e-02, 5.7312e-02,  ..., 1.3113e-06,\n          1.3113e-06, 1.3113e-06],\n         ...,\n         [3.7573e-01, 2.1899e-01, 1.4709e-01,  ..., 5.8413e-06,\n          5.8413e-06, 5.8413e-06],\n         [6.0986e-01, 1.4709e-01, 7.4036e-02,  ..., 2.8014e-06,\n          2.8014e-06, 2.8014e-06],\n         [1.8494e-01, 1.6455e-01, 8.7402e-02,  ..., 2.5094e-05,\n          2.5094e-05, 2.5094e-05]]], device='cuda:0', dtype=torch.float16)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m         probs_seq = torch.ones_like(probs_seq) / probs_seq.size(-\u001b[32m1\u001b[39m)\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Compute entropy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     entropy_per_token = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistributions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs_seq\u001b[49m\u001b[43m)\u001b[49m.entropy()\n\u001b[32m     53\u001b[39m     avg_entropy = entropy_per_token.mean().item()\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m#-------------------------\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Get logits for uncertainty estimation\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# entropy_per_token = torch.distributions.Categorical(probs_seq).entropy()\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# avg_entropy = entropy_per_token.mean().item()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s\\miniconda3\\envs\\samsungProj\\Lib\\site-packages\\torch\\distributions\\categorical.py:81\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, probs, logits, validate_args)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m._num_events = \u001b[38;5;28mself\u001b[39m._param.size()[-\u001b[32m1\u001b[39m]\n\u001b[32m     78\u001b[39m batch_shape = (\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mself\u001b[39m._param.size()[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._param.ndimension() > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch.Size()\n\u001b[32m     80\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s\\miniconda3\\envs\\samsungProj\\Lib\\site-packages\\torch\\distributions\\distribution.py:77\u001b[39m, in \u001b[36mDistribution.__init__\u001b[39m\u001b[34m(self, batch_shape, event_shape, validate_args)\u001b[39m\n\u001b[32m     75\u001b[39m         valid = constraint.check(value)\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._is_all_true(valid):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     78\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m             )\n\u001b[32m     84\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: Expected parameter probs (Tensor of shape (1, 315, 1000)) of distribution Categorical(probs: torch.Size([1, 315, 1000])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([[[8.1848e-02, 3.8971e-02, 3.4515e-02,  ..., 2.3794e-04,\n          2.3794e-04, 2.3794e-04],\n         [1.6357e-01, 1.3232e-01, 9.1614e-02,  ..., 3.3736e-05,\n          3.3736e-05, 3.3736e-05],\n         [7.7295e-01, 7.7087e-02, 5.7312e-02,  ..., 1.3113e-06,\n          1.3113e-06, 1.3113e-06],\n         ...,\n         [3.7573e-01, 2.1899e-01, 1.4709e-01,  ..., 5.8413e-06,\n          5.8413e-06, 5.8413e-06],\n         [6.0986e-01, 1.4709e-01, 7.4036e-02,  ..., 2.8014e-06,\n          2.8014e-06, 2.8014e-06],\n         [1.8494e-01, 1.6455e-01, 8.7402e-02,  ..., 2.5094e-05,\n          2.5094e-05, 2.5094e-05]]], device='cuda:0', dtype=torch.float16)"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "prompt = \"\"\"USER: Write a Python function that implements a graph-based pathfinding algorithm to find the shortest path between two nodes in a weighted, undirected graph, considering both distance and cost constraints. The function should:\n",
    "1. Take a graph (as an adjacency list with weights and costs), start node, end node, and a maximum cost budget as input.\n",
    "2. Return the shortest path (list of nodes) that respects the cost budget, or None if no valid path exists.\n",
    "3. Use Dijkstra’s algorithm with a modified priority queue to account for both distance and cost.\n",
    "4. Include error handling for invalid inputs (e.g., negative weights, non-existent nodes).\n",
    "5. Provide an example usage with a graph containing at least 5 nodes, demonstrating both a successful path and a case where no path fits the budget.\n",
    "\n",
    "Example graph format:\n",
    "graph = {\n",
    "    'A': {'B': (2, 5), 'C': (4, 10)},  \n",
    "    'B': {'A': (2, 5), 'D': (3, 8)},\n",
    "    'C': {'A': (4, 10), 'D': (1, 3), 'E': (5, 12)},\n",
    "    'D': {'B': (3, 8), 'C': (1, 3), 'E': (2, 6)},\n",
    "    'E': {'C': (5, 12), 'D': (2, 6)}\n",
    "AI: \n",
    "}\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=4096)\n",
    "result = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(\"Generated answer:\")\n",
    "print(result)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, return_dict=True)\n",
    "    logits = outputs.logits  \n",
    "    \n",
    "    \n",
    "    if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "        print(\"Warning: NaNs or Infs in logits. Replacing with zeros.\")\n",
    "        logits = torch.where(torch.isnan(logits) | torch.isinf(logits), torch.zeros_like(logits), logits)\n",
    "    \n",
    "    \n",
    "    k = 1000  \n",
    "    top_k_logits, _ = torch.topk(logits, k, dim=-1)\n",
    "    \n",
    "    \n",
    "    log_probs = F.log_softmax(top_k_logits, dim=-1)\n",
    "    probs_seq = torch.exp(log_probs)  \n",
    "    probs_seq = probs_seq + 1e-8  \n",
    "    probs_seq = probs_seq / probs_seq.sum(dim=-1, keepdim=True)  \n",
    "    \n",
    "    \n",
    "    if torch.isnan(probs_seq).any() or torch.isinf(probs_seq).any() or (probs_seq.sum(dim=-1) < 0.99).any():\n",
    "        print(\"Warning: Invalid probabilities detected. Using uniform distribution.\")\n",
    "        probs_seq = torch.ones_like(probs_seq) / probs_seq.size(-1)\n",
    "    \n",
    "    \n",
    "    entropy_per_token = torch.distributions.Categorical(probs_seq).entropy()\n",
    "    avg_entropy = entropy_per_token.mean().item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Avg token entropy: {avg_entropy:.4f}\")\n",
    "print(f\"Allocated VRAM: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Reserved VRAM: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648abeed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsungProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
